{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise.ipynb","provenance":[],"authorship_tag":"ABX9TyPv+Qy2jkxt20JSl5X7qzo0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jqo6k0hPvVQR"},"source":["# 8. Practice training a deep neural network on the CIFAR10 image dataset:"]},{"cell_type":"markdown","metadata":{"id":"-gxgjdlev0oc"},"source":["### a. Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function."]},{"cell_type":"code","metadata":{"id":"My8M3CeRvTFJ","executionInfo":{"status":"ok","timestamp":1627356528747,"user_tz":240,"elapsed":4,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Imports\n","\n","from tensorflow import keras"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ryLicPPpv8G4","executionInfo":{"status":"ok","timestamp":1627356529242,"user_tz":240,"elapsed":252,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"e718c289-08c9-417f-8c3d-93b351f748ea"},"source":["# Creating a sequential model\n","\n","## Clearing Keras backend\n","keras.backend.clear_session()\n","\n","## Creating a sequential model object\n","model = keras.Sequential()\n","\n","## Adding a layer that flattens the dimension\n","model.add(\n","  keras.layers.Flatten(\n","    input_shape=(32,32,3)\n","  )\n",")\n","\n","## Adding 20 Dense layers with 100 nodes using a for loop\n","for i in range(0, 20):\n","  model.add(\n","    keras.layers.Dense(\n","      100, \n","      activation='elu',\n","      kernel_initializer='he_normal'\n","    )\n","  )\n","\n","## Adding an output layer\n","model.add(\n","  keras.layers.Dense(\n","    10,\n","    activation='softmax'\n","  )\n",")\n","\n","model.summary()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 3072)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 100)               307300    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 10)                1010      \n","=================================================================\n","Total params: 500,210\n","Trainable params: 500,210\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6pR5nIFj2vvj"},"source":["### b. Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with *keras.datasets.cifar10.load_data()*. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you’ll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters."]},{"cell_type":"code","metadata":{"id":"G-D3pSZhu0D5","executionInfo":{"status":"ok","timestamp":1627356530139,"user_tz":240,"elapsed":900,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Loading the CIFAR10 data\n","\n","(training_X, training_y), (X_test, y_test) = keras.datasets.cifar10.load_data() "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmTCynznvPHL","executionInfo":{"status":"ok","timestamp":1627356530140,"user_tz":240,"elapsed":5,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"e7d95e71-c7e1-4817-a1cf-6e9d2e82aa03"},"source":["# Viewing the shape of the training and test sets\n","\n","print(f\"Shape of training features: {training_X.shape}\")\n","print(f\"Shape of training target: {training_y.shape}\")\n","print(f\"Shape of test features: {X_test.shape}\")\n","print(f\"Shape of test target: {y_test.shape}\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Shape of training features: (50000, 32, 32, 3)\n","Shape of training target: (50000, 1)\n","Shape of test features: (10000, 32, 32, 3)\n","Shape of test target: (10000, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ffcDFaY3V2g","executionInfo":{"status":"ok","timestamp":1627356530828,"user_tz":240,"elapsed":692,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Scaling the features\n","\n","training_X = training_X/255.\n","X_test = X_test/255."],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2hEzkLhOi4q","executionInfo":{"status":"ok","timestamp":1627356530829,"user_tz":240,"elapsed":21,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"017c69c2-6038-44ae-ecc0-2c0d67427c07"},"source":["# Processing the target variable\n","\n","## Import\n","from tensorflow.keras.utils import to_categorical\n","\n","## Dummifying the target variable\n","training_y = to_categorical(training_y)\n","y_test = to_categorical(y_test)\n","\n","## Viewing the shape of the new target\n","print(f\"Shape of test target: {y_test.shape}\")\n","print(f\"Shape of training target: {training_y.shape}\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Shape of test target: (10000, 10)\n","Shape of training target: (50000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L5VVnVNG5C1c","executionInfo":{"status":"ok","timestamp":1627356530830,"user_tz":240,"elapsed":14,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Splitting train sets further into train and validation sets\n","\n","## Train set\n","X_train = training_X[:45000]\n","y_train = training_y[:45000]\n","\n","## Validation set\n","X_val = training_X[45000:]\n","y_val = training_y[45000:]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"3xOJMMwG4tCn","executionInfo":{"status":"ok","timestamp":1627356530831,"user_tz":240,"elapsed":13,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Compiling the model\n","\n","## Optimizers\n","optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n","\n","model.compile(\n","  optimizer=optimizer,\n","  loss='categorical_crossentropy',\n","  metrics=['accuracy']  \n",")"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpAHe3QS7m_0","executionInfo":{"status":"ok","timestamp":1627356859632,"user_tz":240,"elapsed":328810,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"de9cdca5-e776-4c53-952f-7091780b37b0"},"source":["# Fitting the model\n","\n","callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","\n","model.fit(\n","  X_train,\n","  y_train,\n","  epochs=50,\n","  callbacks=[callback],\n","  validation_data=(X_val, y_val)\n",")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1407/1407 [==============================] - 22s 13ms/step - loss: 2.0866 - accuracy: 0.2317 - val_loss: 2.0583 - val_accuracy: 0.2402\n","Epoch 2/50\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.8650 - accuracy: 0.3152 - val_loss: 1.8462 - val_accuracy: 0.3208\n","Epoch 3/50\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.7957 - accuracy: 0.3494 - val_loss: 2.2091 - val_accuracy: 0.2490\n","Epoch 4/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7434 - accuracy: 0.3711 - val_loss: 1.7598 - val_accuracy: 0.3752\n","Epoch 5/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7025 - accuracy: 0.3910 - val_loss: 1.6968 - val_accuracy: 0.3892\n","Epoch 6/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6698 - accuracy: 0.4042 - val_loss: 1.8498 - val_accuracy: 0.3678\n","Epoch 7/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6396 - accuracy: 0.4136 - val_loss: 1.7600 - val_accuracy: 0.3730\n","Epoch 8/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6176 - accuracy: 0.4232 - val_loss: 1.6564 - val_accuracy: 0.4046\n","Epoch 9/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6016 - accuracy: 0.4303 - val_loss: 1.6799 - val_accuracy: 0.4014\n","Epoch 10/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5746 - accuracy: 0.4409 - val_loss: 1.6879 - val_accuracy: 0.3986\n","Epoch 11/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5636 - accuracy: 0.4461 - val_loss: 1.6506 - val_accuracy: 0.4138\n","Epoch 12/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5526 - accuracy: 0.4486 - val_loss: 1.5704 - val_accuracy: 0.4514\n","Epoch 13/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5293 - accuracy: 0.4546 - val_loss: 1.5696 - val_accuracy: 0.4498\n","Epoch 14/50\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.5199 - accuracy: 0.4629 - val_loss: 1.6054 - val_accuracy: 0.4334\n","Epoch 15/50\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.5048 - accuracy: 0.4665 - val_loss: 1.6110 - val_accuracy: 0.4480\n","Epoch 16/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5686 - accuracy: 0.4380 - val_loss: 1.7104 - val_accuracy: 0.3762\n","Epoch 17/50\n","1407/1407 [==============================] - 18s 12ms/step - loss: 174.8010 - accuracy: 0.2905 - val_loss: 1.8713 - val_accuracy: 0.2994\n","Epoch 18/50\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.8029 - accuracy: 0.3299 - val_loss: 1.7979 - val_accuracy: 0.3346\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff4df6585d0>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YS39d6XUUAZH","executionInfo":{"status":"ok","timestamp":1627356918562,"user_tz":240,"elapsed":59010,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"5d35f1d5-ab0f-4700-ba7b-57347162caa9"},"source":["# Predicting on the test set\n","\n","model_predictions = model.predict(X_test)\n","model_predictions[0]"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.030517  , 0.03003925, 0.07990684, 0.26049998, 0.06207043,\n","       0.24870089, 0.2160871 , 0.04242021, 0.01084487, 0.01891342],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"s7ZCvoBgUoV1","executionInfo":{"status":"ok","timestamp":1627357313184,"user_tz":240,"elapsed":413,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"85f50977-bf9c-4997-b839-fb0eec69549d"},"source":["# Plotting images\n","\n","import matplotlib.pyplot as plt\n","\n","cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","plt.imshow(X_test[0])\n","plt.title(cifar_classes[keras.backend.argmax(y_test[0])]+\" : \"+cifar_classes[keras.backend.argmax(model_predictions[0])])\n"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'cat : cat')"]},"metadata":{"tags":[]},"execution_count":32},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"rBJPU5ZlP1jC"},"source":["### c. Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADeKDFig8vwy","executionInfo":{"status":"ok","timestamp":1627357325757,"user_tz":240,"elapsed":805,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"6b1d8d09-1553-4cff-e9c5-7763e8626b84"},"source":["# Creating a sequential model\n","\n","## Clearing Keras backend\n","keras.backend.clear_session()\n","\n","## Creating a sequential model object\n","batch_model = keras.Sequential()\n","\n","## Adding a layer that flattens the dimension\n","batch_model.add(\n","  keras.layers.Flatten(\n","    input_shape=(32,32,3)\n","  )\n",")\n","\n","## Adding 20 Dense layers with 100 nodes using a for loop\n","for i in range(0, 20):\n","  \n","  ### Adding Dense layer without activation\n","  batch_model.add(\n","    keras.layers.Dense(\n","      100, \n","      kernel_initializer='he_normal'\n","    )\n","  )\n","\n","  ### Adding Batch Normalization\n","  batch_model.add(\n","    keras.layers.BatchNormalization()\n","  )\n","\n","  ### Adding Activation layer\n","  batch_model.add(\n","      keras.layers.Activation('elu')\n","  )\n","\n","## Adding an output layer\n","batch_model.add(\n","  keras.layers.Dense(\n","    10,\n","    activation='softmax'\n","  )\n",")\n","\n","batch_model.summary()"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 3072)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 100)               307300    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 100)               400       \n","_________________________________________________________________\n","activation (Activation)      (None, 100)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 100)               400       \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 100)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_18 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 100)               400       \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 100)               0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 10)                1010      \n","=================================================================\n","Total params: 508,210\n","Trainable params: 504,210\n","Non-trainable params: 4,000\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kr3mdHJBT3-e","executionInfo":{"status":"ok","timestamp":1627357330477,"user_tz":240,"elapsed":280,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Compiling the model\n","\n","## Optimizers\n","optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n","\n","batch_model.compile(\n","  optimizer=optimizer,\n","  loss='categorical_crossentropy',\n","  metrics=['accuracy']  \n",")"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OcjhHK0YsRh","executionInfo":{"status":"ok","timestamp":1627358672520,"user_tz":240,"elapsed":1340295,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"23636dae-15ab-48c4-cc2f-981e04090748"},"source":["# Fitting the model\n","\n","batch_model.fit(\n","  X_train,\n","  y_train,\n","  epochs=50,\n","  callbacks=[callback],\n","  validation_data=(X_val, y_val)\n",")"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1407/1407 [==============================] - 91s 18ms/step - loss: 1.8335 - accuracy: 0.3392 - val_loss: 1.8871 - val_accuracy: 0.3436\n","Epoch 2/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.6775 - accuracy: 0.4021 - val_loss: 1.7343 - val_accuracy: 0.3788\n","Epoch 3/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.6116 - accuracy: 0.4255 - val_loss: 1.5785 - val_accuracy: 0.4346\n","Epoch 4/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.5610 - accuracy: 0.4456 - val_loss: 1.7002 - val_accuracy: 0.3968\n","Epoch 5/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 1.5192 - accuracy: 0.4621 - val_loss: 1.5738 - val_accuracy: 0.4300\n","Epoch 6/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.4774 - accuracy: 0.4794 - val_loss: 1.5731 - val_accuracy: 0.4568\n","Epoch 7/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.4425 - accuracy: 0.4898 - val_loss: 1.5147 - val_accuracy: 0.4630\n","Epoch 8/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.4109 - accuracy: 0.5031 - val_loss: 1.5788 - val_accuracy: 0.4392\n","Epoch 9/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.3835 - accuracy: 0.5104 - val_loss: 1.5477 - val_accuracy: 0.4492\n","Epoch 10/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.3562 - accuracy: 0.5207 - val_loss: 1.5232 - val_accuracy: 0.4654\n","Epoch 11/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.3342 - accuracy: 0.5309 - val_loss: 1.5736 - val_accuracy: 0.4368\n","Epoch 12/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 1.3162 - accuracy: 0.5381 - val_loss: 1.7700 - val_accuracy: 0.3986\n","Epoch 13/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.2887 - accuracy: 0.5483 - val_loss: 1.5896 - val_accuracy: 0.4588\n","Epoch 14/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.2722 - accuracy: 0.5537 - val_loss: 1.6118 - val_accuracy: 0.4340\n","Epoch 15/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 1.2584 - accuracy: 0.5612 - val_loss: 1.4600 - val_accuracy: 0.4938\n","Epoch 16/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.2358 - accuracy: 0.5666 - val_loss: 1.5815 - val_accuracy: 0.4652\n","Epoch 17/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 1.2201 - accuracy: 0.5736 - val_loss: 1.4852 - val_accuracy: 0.4948\n","Epoch 18/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 1.1974 - accuracy: 0.5784 - val_loss: 1.6172 - val_accuracy: 0.4418\n","Epoch 19/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 1.1860 - accuracy: 0.5854 - val_loss: 1.4823 - val_accuracy: 0.4856\n","Epoch 20/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.1647 - accuracy: 0.5913 - val_loss: 1.5117 - val_accuracy: 0.4768\n","Epoch 21/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.1508 - accuracy: 0.5947 - val_loss: 1.6230 - val_accuracy: 0.4568\n","Epoch 22/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.1340 - accuracy: 0.6021 - val_loss: 1.5262 - val_accuracy: 0.4772\n","Epoch 23/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 1.1265 - accuracy: 0.6032 - val_loss: 1.5245 - val_accuracy: 0.4884\n","Epoch 24/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.1144 - accuracy: 0.6079 - val_loss: 1.3909 - val_accuracy: 0.5114\n","Epoch 25/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0966 - accuracy: 0.6158 - val_loss: 1.4615 - val_accuracy: 0.4946\n","Epoch 26/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0894 - accuracy: 0.6173 - val_loss: 1.7404 - val_accuracy: 0.4604\n","Epoch 27/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0672 - accuracy: 0.6244 - val_loss: 1.6347 - val_accuracy: 0.4826\n","Epoch 28/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0564 - accuracy: 0.6300 - val_loss: 1.4825 - val_accuracy: 0.4898\n","Epoch 29/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0481 - accuracy: 0.6314 - val_loss: 1.4615 - val_accuracy: 0.5188\n","Epoch 30/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0351 - accuracy: 0.6362 - val_loss: 1.5322 - val_accuracy: 0.4902\n","Epoch 31/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0231 - accuracy: 0.6416 - val_loss: 1.5245 - val_accuracy: 0.4996\n","Epoch 32/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 1.0107 - accuracy: 0.6482 - val_loss: 1.5415 - val_accuracy: 0.5036\n","Epoch 33/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 0.9980 - accuracy: 0.6514 - val_loss: 1.4587 - val_accuracy: 0.5240\n","Epoch 34/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.9908 - accuracy: 0.6535 - val_loss: 1.4592 - val_accuracy: 0.5164\n","Epoch 35/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.9755 - accuracy: 0.6600 - val_loss: 1.6258 - val_accuracy: 0.4798\n","Epoch 36/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 0.9695 - accuracy: 0.6604 - val_loss: 1.5051 - val_accuracy: 0.5140\n","Epoch 37/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.9538 - accuracy: 0.6678 - val_loss: 1.4828 - val_accuracy: 0.5140\n","Epoch 38/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.9501 - accuracy: 0.6692 - val_loss: 1.4342 - val_accuracy: 0.5070\n","Epoch 39/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 0.9391 - accuracy: 0.6695 - val_loss: 1.4222 - val_accuracy: 0.5324\n","Epoch 40/50\n","1407/1407 [==============================] - 25s 18ms/step - loss: 0.9292 - accuracy: 0.6756 - val_loss: 1.5869 - val_accuracy: 0.4888\n","Epoch 41/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.9160 - accuracy: 0.6822 - val_loss: 1.6390 - val_accuracy: 0.4770\n","Epoch 42/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.9185 - accuracy: 0.6810 - val_loss: 1.5561 - val_accuracy: 0.5056\n","Epoch 43/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.9012 - accuracy: 0.6855 - val_loss: 1.5381 - val_accuracy: 0.5084\n","Epoch 44/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.8969 - accuracy: 0.6855 - val_loss: 1.6709 - val_accuracy: 0.4702\n","Epoch 45/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.8838 - accuracy: 0.6925 - val_loss: 1.6121 - val_accuracy: 0.5048\n","Epoch 46/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.8693 - accuracy: 0.6943 - val_loss: 1.6319 - val_accuracy: 0.4862\n","Epoch 47/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.8677 - accuracy: 0.6968 - val_loss: 1.6102 - val_accuracy: 0.4952\n","Epoch 48/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.8621 - accuracy: 0.7001 - val_loss: 1.5659 - val_accuracy: 0.4984\n","Epoch 49/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.8520 - accuracy: 0.7024 - val_loss: 1.7174 - val_accuracy: 0.4698\n","Epoch 50/50\n","1407/1407 [==============================] - 26s 18ms/step - loss: 0.8462 - accuracy: 0.7036 - val_loss: 1.4932 - val_accuracy: 0.5302\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff4dce66f90>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"A0B5iGg9Y-2f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627358673687,"user_tz":240,"elapsed":1204,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"97582e1f-5861-4576-9507-ad82bd67d807"},"source":["# Predicting on the test set\n","\n","model_predictions = batch_model.predict(X_test)\n","model_predictions[0]"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.02146082, 0.07796101, 0.03982396, 0.4053529 , 0.29558486,\n","       0.07776496, 0.0035156 , 0.02354605, 0.04243474, 0.01255515],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"jrQtx4ABFg6U"},"source":["### d. Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.)."]},{"cell_type":"code","metadata":{"id":"IiHVZ5NOGXEN","executionInfo":{"status":"ok","timestamp":1627358677655,"user_tz":240,"elapsed":3977,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Normalizing the data\n","\n","def normalize_data(data1, data2):\n","  v_min = data1.min(axis=(0, 1), keepdims=True)\n","  v_max = data1.max(axis=(0, 1), keepdims=True)\n","  return (data2 - v_min)/(v_max - v_min)\n","\n","X_train_norm = normalize_data(X_train, X_train)\n","X_val_norm = normalize_data(X_train, X_val)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"DcXXNAFkFgYA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627359232595,"user_tz":240,"elapsed":427,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"0d161bdd-00f3-433a-f0b4-f17fe0ab867a"},"source":["# Creating a sequential model\n","\n","## Clearing Keras backend\n","keras.backend.clear_session()\n","\n","## Creating a sequential model object\n","selu_model = keras.Sequential()\n","\n","## Adding a layer that flattens the dimension\n","selu_model.add(\n","  keras.layers.Flatten(\n","    input_shape=(32,32,3)\n","  )\n",")\n","\n","## Adding 20 Dense layers with 100 nodes using a for loop\n","for i in range(0, 20):\n","  \n","  ### Adding Dense layer without activation\n","  selu_model.add(\n","    keras.layers.Dense(\n","      100, \n","      kernel_initializer='lecun_normal',\n","      activation='selu'\n","    )\n","  )\n","\n","## Adding an output layer\n","selu_model.add(\n","  keras.layers.Dense(\n","    10,\n","    activation='softmax'\n","  )\n",")\n","\n","selu_model.summary()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 3072)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 100)               307300    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 100)               10100     \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 10)                1010      \n","=================================================================\n","Total params: 500,210\n","Trainable params: 500,210\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fbgVe_KEEYB-","executionInfo":{"status":"ok","timestamp":1627359235459,"user_tz":240,"elapsed":8,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}}},"source":["# Compiling the model\n","\n","## Optimizers\n","optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n","\n","selu_model.compile(\n","  optimizer=optimizer,\n","  loss='categorical_crossentropy',\n","  metrics=['accuracy']  \n",")"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQ48bjosEhgT","executionInfo":{"status":"ok","timestamp":1627359529225,"user_tz":240,"elapsed":291306,"user":{"displayName":"Taraqur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKLMV7tt14yUoJgEibaSKubcsvu9TOMY42Z_6vKw=s64","userId":"08236191007596163450"}},"outputId":"5364ef90-030e-4b0b-d9cd-a3856444560f"},"source":["# Fitting the model\n","\n","selu_model.fit(\n","  X_train_norm,\n","  y_train,\n","  epochs=50,\n","  callbacks=[callback],\n","  validation_data=(X_val_norm, y_val)\n",")"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1407/1407 [==============================] - 22s 13ms/step - loss: 2.1558 - accuracy: 0.1811 - val_loss: 2.0227 - val_accuracy: 0.2342\n","Epoch 2/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.9690 - accuracy: 0.2534 - val_loss: 2.0178 - val_accuracy: 0.2534\n","Epoch 3/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.9501 - accuracy: 0.2644 - val_loss: 2.1240 - val_accuracy: 0.1808\n","Epoch 4/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.9624 - accuracy: 0.2476 - val_loss: 1.9339 - val_accuracy: 0.2634\n","Epoch 5/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.8741 - accuracy: 0.2904 - val_loss: 1.8729 - val_accuracy: 0.2930\n","Epoch 6/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.8679 - accuracy: 0.2902 - val_loss: 1.8502 - val_accuracy: 0.2872\n","Epoch 7/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.8536 - accuracy: 0.2967 - val_loss: 1.8242 - val_accuracy: 0.3128\n","Epoch 8/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7970 - accuracy: 0.3220 - val_loss: 1.7872 - val_accuracy: 0.3314\n","Epoch 9/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7910 - accuracy: 0.3251 - val_loss: 1.7614 - val_accuracy: 0.3466\n","Epoch 10/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7558 - accuracy: 0.3436 - val_loss: 1.7290 - val_accuracy: 0.3544\n","Epoch 11/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7298 - accuracy: 0.3510 - val_loss: 1.8300 - val_accuracy: 0.3178\n","Epoch 12/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7131 - accuracy: 0.3612 - val_loss: 1.7749 - val_accuracy: 0.3356\n","Epoch 13/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7077 - accuracy: 0.3686 - val_loss: 1.7738 - val_accuracy: 0.3386\n","Epoch 14/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.8503 - accuracy: 0.3023 - val_loss: 1.8522 - val_accuracy: 0.2812\n","Epoch 15/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7982 - accuracy: 0.3204 - val_loss: 1.7759 - val_accuracy: 0.3480\n","Epoch 16/50\n","1407/1407 [==============================] - 18s 13ms/step - loss: 8.7758 - accuracy: 0.3094 - val_loss: 1.8824 - val_accuracy: 0.2678\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7ff4dd6e2c90>"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"5cClovFEGcvg"},"source":["### 5. Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout."]},{"cell_type":"code","metadata":{"id":"duJR6EnVAgfW"},"source":["# Creating a sequential model with Alpha Dropout\n","\n","## Clearing Keras backend\n","keras.backend.clear_session()\n","\n","## Creating a sequential model object\n","alpha_model = keras.Sequential()\n","\n","## Adding a layer that flattens the dimension\n","alpha_model.add(\n","  keras.layers.Flatten(\n","    input_shape=(32,32,3)\n","  )\n",")\n","\n","## Adding 20 Dense layers with 100 nodes using a for loop\n","for i in range(0, 20):\n","  \n","  ### Adding Dense layer without activation\n","  alpha_model.add(\n","    keras.layers.Dense(\n","      100, \n","      kernel_initializer='lecun_normal',\n","      activation='selu'\n","    )\n","  )\n","\n","  ### Adding AlphaDropout\n","  alpha_model.add(\n","    keras.layers.AlphaDropout(\n","      rate=0.3\n","    )\n","  )\n","\n","## Adding an output layer\n","alpha_model.add(\n","  keras.layers.Dense(\n","    10,\n","    activation='softmax'\n","  )\n",")\n","\n","alpha_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7BbCOrjK78p"},"source":["# Compiling the model\n","\n","## Optimizers\n","optimizer = keras.optimizers.Nadam(learning_rate=0.001)\n","\n","alpha_model.compile(\n","  optimizer=optimizer,\n","  loss='categorical_crossentropy',\n","  metrics=['accuracy']  \n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4n9Dn-UhLBZQ"},"source":["# Fitting the model\n","\n","alpha_model.fit(\n","  X_train_norm,\n","  y_train,\n","  epochs=50,\n","  callbacks=[callback],\n","  validation_data=(X_val_norm, y_val)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sO-0r_q8Gk8h"},"source":["### 6. Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy."]},{"cell_type":"code","metadata":{"id":"1qy0i10DGSrN"},"source":["# Retraining model using "],"execution_count":null,"outputs":[]}]}